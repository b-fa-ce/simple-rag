# The provider for the AI models to use.
MODEL_PROVIDER=ollama

# The name of LLM model to use.
MODEL=gemma2:2b

# Name of the embedding model to use.
EMBEDDING_MODEL=nomic-embed-text

# Dimension of the embedding model to use.
EMBEDDING_DIM=768

# The questions to help users get started (multi-line).
# CONVERSATION_STARTERS=

# The base URL for the Ollama API. Eg: http://127.0.0.1:11434
OLLAMA_BASE_URL=http://localhost:11434

# The timeout for the Ollama API requests in milliseconds.
OLLAMA_REQUEST_TIMEOUT="60000"

# Set environment to development or production.
ENVIRONMENT=development

# Specify the port and host for the backend server.
APP_PORT=8000
APP_HOST=0.0.0.0

# The number of similar embeddings to return when retrieving documents.
# TOP_K="2"

# The system prompt for the AI model.
SYSTEM_PROMPT="You are a chatbot, able to have normal interactions, as well as talk"

# An additional system prompt to add citation when responding to user questions.
SYSTEM_CITATION_PROMPT='You have provided information from a knowledge base that has been passed to you in nodes of information.
Each node has useful metadata such as node ID, file name, page, etc.
Please add the citation to the data node for each sentence or paragraph that you reference in the provided information.
The citation format is: . [citation:<node_id>]()
Where the <node_id> is the unique identifier of the data node.

Example:
We have two nodes:
  node_id: xyz
  file_name: llama.pdf

  node_id: abc
  file_name: animal.pdf

User question: Tell me a fun fact about Llama.
Your answer:
A baby llama is called "Cria" [citation:xyz]().
It often live in desert [citation:abc]().
It\'s cute animal.
'
